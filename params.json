{"name":"MC-VOSM","tagline":"Multi-channel ASM enhancements to VOSM","body":"Multi-channel ASM enhancements to the [Visual Open Statistical Models project](http://www.visionopen.com/)\r\nMC-VOSM also provides automated testing and graphing capabilities to augment VOSM's flexible AAM/ASM library.\r\n\r\n## How to Use\r\n1. [Clone this repository](https://github.com/cpb8010/mc-vosm.git)\r\n2. [Install and configure required libraries](https://github.com/cpb8010/mc-vosm/wiki/Setup)\r\n3. Download a sample face database (if you don't already have one) eg: [Jia Pei's](http://visionopen.com/cv/databases/JIAPEI/)[FRANCK](http://personalpages.manchester.ac.uk/staff/timothy.f.cootes/data/talking_face/talking_face.html)\r\n4. Compile and run [test_smbuilding](https://github.com/cpb8010/mc-vosm/wiki/Model-building-walkthrough) and [test_smfitting](https://github.com/cpb8010/mc-vosm/wiki/Fitting-walkthrough) programs\r\n5. In Python, call [graphing functions](https://github.com/cpb8010/mc-vosm/wiki/Testing-and-Graphing-Results) to display a summary of results\r\n\r\nMore help can be found on the [wiki](https://github.com/cpb8010/mc-vosm/wiki)\r\n\r\n## Origin\r\nForked from [VOSM 0.3.3](http://www.visionopen.com/downloads/open-source-software/VOSM/)\r\n\r\nThe core VOSM package implements multiple AAM and ASM techniques.\r\nIt supports a few annotation formats and is designed for faces.\r\n\r\n## Current state\r\nMC-VOSM is a fork of VOSM that is independently maintained with a focus on Active Shape Model enhancements for color+depth image processing and improved result reporting.\r\nThe multi-channel ASM techniques have been tested on the [Bosphorus Facial Expression Database](http://bosphorus.ee.boun.edu.tr/default.aspx)\r\n\r\nThe results for the above data-set are published in an ICIP2013 paper <Link TDB>\r\n\r\n### Features\r\n* 3 New multi-channel fitting techniques\r\n* 2 New initial shape placement techniques\r\n* Automated cross validation testing\r\n* Automated result collection and graph generation\r\n* Support for Bosphorus depth images and annotation information\r\n* Up to 3 image channels supported for building and fitting\r\n\r\n\r\n### Current external dependencies\r\nOlder versions of these libraries might work, but the versions listed have been verified\r\nC++ is for building VOSM; the ASM building and fitting programs\r\nPython is required for automating testing and graph generation\r\n\r\n* C++\r\n  * [Boost v1.53](http://www.boost.org/)\r\n      * Only uses boost::filesystem, so older versions work fine too\r\n  * [OpenCV 2.4.5](http://opencv.org/)\r\n      * Requires 2.4 or newer because of Mat syntax changes\r\n  * [YAML-CPP 0.5.1](http://code.google.com/p/yaml-cpp/)\r\n  * [*Visual Studio 2012*](http://www.microsoft.com/visualstudio/eng/downloads#d-2012-express)\r\n      * Windows only :( until CMake file are updated, other platforms remain untested\r\n      * All .sln and .vxproj were converted to vs2012 any may not be backwards compatible\r\n      \r\nThe most recent versions of the below are suggested\r\n* [Python 2.7](http://www.python.org/download/)\r\n  * [Matplotlib](http://matplotlib.org/downloads.html)\r\n  * [NumPy](http://www.numpy.org/)\r\n  * [SciPy](http://www.scipy.org/)\r\n  * [Pandas](http://pandas.pydata.org/)\r\n  * [SciKit-Learn](http://scikit-learn.org/stable/install.html)\r\n  \r\n# Expected Use Case\r\nAs a completely open source library, MC-VOSM can serve as a base for testing new ASM techniques or new face databases.\r\nGiven a new database of faces with facial feature point information and a compiling version of mc-vosm, the following is necessary to fully test the new database or method with MC-VOSM:\r\n\r\n1. A [shape-info file](https://github.com/cpb8010/mc-vosm/wiki/shape_info_example), detailing how each facial feature point relates to its neighbors and relative to the face.\r\n2. A Python function to convert (if necessary) and sort images based on types or experimental parameters\r\n  * The test python scripts expect a certain directory structure. See [the wiki page for details](https://github.com/cpb8010/mc-vosm/wiki/Testing-and-Graphing-Results)\r\n3. An optional C++ code path to implement a new ASM technique (if testing a new ASM technique)\r\n  * An additional YAML parameter to enable/disable that code path\r\n* If annotation format is not supported, C++ code to read annotation file format into VOSM.\r\n  * An additional YAML setting for the new annotation file format\r\n\r\nAfter these steps are completed, running [crossValTest.py](https://github.com/cpb8010/mc-vosm/blob/master/reporting/crossValTest.py) will call your convert and sorting functions to create N(default 10) validation folds.\r\nThe script will then automatically train all the necessary models and run all of the fitting tests.\r\nMC-VOSM will record the results as images and text files, which is then scraped into a database for graphing as part of the test script.\r\nThe script will then plot the accuracy and efficiency results for each sorted group across all the validation folds.\r\n\r\n#### Additional notes\r\n* Real-time tracking is supported in the test program, but has not been tested or evaluated.\r\n* The test_smfitting and test_smbuilding programs are examples for the VOSM library interface.\r\n* AAM techniques are left unchanged from VOSM, but will use the same result reporting functions.\r\n  * For questions about AAM techniques, check out the VOSM site; MC-VOSM only considers ASM for now.\r\n* More detailed changes from VOSM are listed [here](VOSM_changelist.txt)\r\n\r\n\r\n### About the author\r\nThis work was created as part of my [master's thesis](https://ritdml.rit.edu/bitstream/handle/1850/16094/CBellmoreThesis11-2012.pdf?sequence=1) at [R.I.T.](http://www.rit.edu/) and I have permission from VOSM's primary author, Jia Pei, to publish my enhancements here.\r\n\r\nThis work was done under the supervision of my adviser, [Andreas Savakis](http://www.ce.rit.edu/people/savakis/).\r\n\r\nI love talking about this work and trying new things, so please contact [me](mailto:cpb8010@g.rit.edu) with any comments or questions!\r\n","google":"UA-34067685-1","note":"Don't delete this file! It's used internally to help with page regeneration."}